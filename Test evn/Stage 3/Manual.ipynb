{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "482fc1c869169fa2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# importing necessary libraries, modules and functions\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "\n",
    "from Functions.Validations.Validation import summary,LivePD_Validation, Vintage_Validation,Score_Binning_Validation\n",
    "from Functions.General.FilesFlow import make_directory, current_path_and_path_list\n",
    "from Functions.General.Module import WoeAnalysis, WoE_Binning, CreditScoring\n",
    "from Functions.Validations.Validation import cutoff, cutoff_plot\n",
    "from Functions.Visualisation.Heatmap import correlation_heatmap\n",
    "from Functions.Visualisation.Lineplot import Lineplot\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "import dill\n",
    "\n",
    "\n",
    "# suppresses all warnings generated by the Python warnings module. \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set the maximum number of columns to be displayed when printing a DataFrame to None,\n",
    "# pandas will display all columns of the DataFrame without truncating or hiding any columns\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "id": "96fba8c3321dc70d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Path Control & Global Variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2d78222347544dd"
  },
  {
   "cell_type": "code",
   "source": [
    "# Obtaining the current path and list of directories in the path\n",
    "curr_path, path_parts = current_path_and_path_list()\n",
    "\n",
    "# Defining the path of the raw data to be imported\n",
    "raw_dir = str(curr_path.parents[2]) + \"\\\\Data\\\\Raw Data\\\\\"\n",
    "\n",
    "# Defining the path where processed data will be saved\n",
    "proc_dir = make_directory(raw_dir[:-14] + \"Data\\\\Scorecards\\\\\" + path_parts[-2] + \"\\\\Processed Data\\\\\")\n",
    "res_dir = make_directory(raw_dir[:-14] + \"Data\\\\Scorecards\\\\\" + path_parts[-2] + \"\\\\Results\\\\\")\n",
    "res_data_plt_dir = make_directory(raw_dir[:-14] + \"Data\\\\Scorecards\\\\\" + path_parts[-2] + \"\\\\Results\\\\Data (Plot)\\\\\")\n",
    "res_data_exl_dir = make_directory(raw_dir[:-14] + \"Data\\\\Scorecards\\\\\" + path_parts[-2] + \"\\\\Results\\\\Data (Excel)\\\\\")\n",
    "res_data_pkl_dir = make_directory(raw_dir[:-14] + \"Data\\\\Scorecards\\\\\" + path_parts[-2] + \"\\\\Results\\\\Data (Pickle)\\\\\")\n",
    "model_dir = make_directory(raw_dir[:-14] + \"Data\\\\Scorecards\\\\\" + path_parts[-2] + \"\\\\Model Flow\\\\\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af35dd2ac87e96f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25756656981cb28d"
  },
  {
   "cell_type": "code",
   "source": [
    "# reading pandas DataFrame from a pickle file \n",
    "df = pd.read_pickle(proc_dir + \"Data S2.pkl\")\n",
    "PDLive = pd.read_pickle(raw_dir + \"PDLive.pkl\")\n",
    "allApproved_df = pd.read_pickle(proc_dir + \"Data S2 Approved.pkl\")\n",
    "Rejected_df = pd.read_pickle(proc_dir + \"Data S2 Rejected.pkl\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d182c3d89c4021e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bad client rates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "166988346cced9d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the total number of records where \"LoanId\" not NaN\n",
    "total = df[~df[\"LoanId\"].isna()][\"Actual\"].value_counts()[1] + df[~df[\"LoanId\"].isna()][\"Actual\"].value_counts()[0]\n",
    "\n",
    "\n",
    "# calculating the percentage of bad customers\n",
    "bads = round((df[~df[\"LoanId\"].isna()][\"Actual\"].value_counts()[0]/total) * 100,2)\n",
    "\n",
    "\n",
    "# printing values of good & bad and percentage of bad\n",
    "print(f\"\"\"Good: {df[~df['LoanId'].isna()]['Actual'].value_counts()[1]}\n",
    "Bad: {df[~df['LoanId'].isna()]['Actual'].value_counts()[0]}\n",
    "Weight of bad customers is:  {bads}%  \"\"\")\n"
   ],
   "id": "5b20da5b3a28b8f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1346e98aaff208f8"
  },
  {
   "cell_type": "code",
   "source": [
    "# dropping actual column from dataframe\n",
    "X = df.drop(columns=['Actual'])\n",
    "\n",
    "# taking only actual column from dataframe \n",
    "y = df['Actual']\n",
    "\n",
    "# intialising WoeAnalysis class\n",
    "woe_analysis = WoeAnalysis()\n",
    "\n",
    "# split dataset into train/test parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y,random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aa1d719c9802c3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discrete Features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3df22b642381e64c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Purpose"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "276b7baba50d0ffc"
  },
  {
   "cell_type": "code",
   "source": [
    "woe_analysis.discrete(column=\"Purpose\", df=X_train, target=y_train).plot()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49b9fd1768a2790e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RejectReasonName"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61d2bf9e485a5e62"
  },
  {
   "cell_type": "code",
   "source": [
    "woe_analysis.discrete(column=\"RejectReasonName\", df=X_train, target=y_train).plot()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "252336f46727e872",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PayTimeCategory"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ade173686e3d486c"
  },
  {
   "cell_type": "code",
   "source": [
    "woe_analysis.discrete(column=\"PayTimeCategory\", df=X_train, target=y_train).plot()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0164c861d3a7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### MaritalStatus"
   ],
   "id": "99d54e07892c72ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "woe_analysis.discrete(column=\"MaritalStatus\", df=X_train, target=y_train).plot()"
   ],
   "id": "26ab8672daae007d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RiskGrade"
   ],
   "id": "b2738429905212aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "woe_analysis.discrete(column=\"RiskGrade\", df=X_train, target=y_train).plot()"
   ],
   "id": "2244633df0c0318d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ActiveHistory_PreviousPdSum"
   ],
   "id": "9fe006e4e2ebaaea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "woe_analysis.discrete(column=\"ActiveHistory_PreviousPdSum\", df=X_train, target=y_train).plot()"
   ],
   "id": "2ffaa8169abbf56d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<br><br><br><br>\n",
    "## Continuous Features"
   ],
   "id": "442a87a44d11e8ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Last12Months"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7005404ad2ecd1ab"
  },
  {
   "cell_type": "code",
   "source": [
    "bins = pd.IntervalIndex.from_tuples([(-50,-0.1),(-0.1, 1), (1, 2),(2,3),(3,4),(4,5),(5,6),(6,8),(8,11),(11,15),(15,20),(20,30),(30, np.inf)])\n",
    "woe_analysis.continuous(column=\"Last12Months\", bins= bins,df=X_train, target=y_train).plot(rotation=90)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f4a968dccae2233",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RefinanceRate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7ce9e74fc0e35e4"
  },
  {
   "cell_type": "code",
   "source": [
    "bins = pd.IntervalIndex.from_tuples([(-1,0),(0, 0.2), (0.2,0.35), (0.35, 0.45),(0.45, 0.55), (0.55, 0.65),(0.65, np.inf)])\n",
    "woe_analysis.continuous(column=\"RefinanceRate\", bins= bins,df=X_train, target=y_train).plot(rotation=90)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3af0d2e2baf3f8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RejectedAppCount"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b016e755563977e0"
  },
  {
   "cell_type": "code",
   "source": [
    "bins = pd.IntervalIndex.from_tuples([(-50,0),(0,1),(1,2),(2,3),(3,np.inf)])\n",
    "woe_analysis.continuous(column=\"RejectedAppCount\", bins= bins,df=X_train, target=y_train).plot(rotation=90)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ca95d5c455a3145",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br><br><br><br><br><br><br><br>\n",
    "# Export data for stage 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4910c36b8464a2"
  },
  {
   "cell_type": "code",
   "source": [
    "# create a DataFrame with a single column named \"name\" containing values extracted from WoE_dict\n",
    "# for each item in WoE_dict, split the string at \":\" and take the first part (before \":\")\n",
    "# convert the resulting list into a DataFrame and extract unique values from the \"name\" column\n",
    "# convert the unique values back into a list\n",
    "WoE_dict = woe_analysis.WoE_dict\n",
    "\n",
    "# names of variables\n",
    "names = list(pd.DataFrame({\"name\":[i.split(\":\")[0] for i in WoE_dict ]})[\"name\"].unique())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d2c4991a6e3a146",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Coreelations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c985ac71f39977e9"
  },
  {
   "cell_type": "code",
   "source": [
    "# taking the dataframe filtered with variables necessary for model \n",
    "X = X[names]\n",
    "X_train = X_train[names]\n",
    "\n",
    "woe_transform = WoE_Binning(WoE_dict= WoE_dict, Production=False)\n",
    "X_transformed = woe_transform.transform(X)\n",
    "\n",
    "correlation_heatmap(X_transformed, target = y)\n",
    "sizz = X_transformed.shape[1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5db0ae13bab90c86",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Evaluateing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc0dfce010d7651f"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def evaluate_model(pipeline):\n",
    "    # pipeline: there is passes pipeline\n",
    "    ''' function that evaluates models performance '''\n",
    "    def plot_cm(y_true, y_pred):\n",
    "        # y_true: actual value of target (type: series)\n",
    "        # y_pred: predicted value of target (type: series)\n",
    "\n",
    "\n",
    "        # Calculate the confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "\n",
    "        # Create a DataFrame from the confusion matrix\n",
    "        df_cm = pd.DataFrame(cm)\n",
    "\n",
    "        # seaborn setting style axis names and plotting\n",
    "        sns.set(font_scale=1.4)\n",
    "        sns.heatmap(df_cm, annot=True, annot_kws={\"size\":16}, fmt='g', cmap='Blues')\n",
    "        plt.title('CPA Consumer\\n')\n",
    "        plt.xlabel(\"Predicited\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.show()\n",
    "\n",
    "    # prediction\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "    # invert the predicted labels and true labels (changing 0s to 1s and 1s to 0s)\n",
    "    y_pred, y_test_hat = [1^x for x in y_pred], [1^x for x in y_test]\n",
    "\n",
    "\n",
    "    # Calculate accuracy, ROC-AUC, and Gini coefficient\n",
    "    acc, roc_auc = accuracy_score(y_test_hat, y_pred), roc_auc_score(y_test_hat, y_pred)\n",
    "\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}, ROC-AUC: {roc_auc:.4f}, gini: {2*roc_auc-1:.4f}\\n\")\n",
    "    print(classification_report(y_test_hat, y_pred))\n",
    "    plot_cm(y_test_hat, y_pred)\n",
    "    class_report = classification_report(y_test_hat, y_pred, output_dict=True)\n",
    "\n",
    "    print(f'''\n",
    "საერთო აკურატულობა: {acc*100:.3f} %\n",
    "რეალურად დაიფარა {class_report[\"0\"][\"support\"]}-ი სესხი\n",
    "რეალურად გაფუჭდა  {class_report[\"1\"][\"support\"]}-ი სესხი\n",
    "\n",
    "მოდელმა დააპროგნოზა {class_report[\"0\"][\"recall\"]*class_report[\"0\"][\"support\"] + (1-class_report[\"1\"][\"recall\"])*class_report[\"1\"][\"support\"]} სესხის დაფარვა, საიდანაც რეალურად დაფარული იყო {str(round(class_report[\"0\"][\"precision\"], 4)*100)[0:5]} % ანუ {class_report[\"0\"][\"recall\"]*class_report[\"0\"][\"support\"]} სესი.\n",
    "\n",
    "მოდელმა დააპროგნოზა {class_report[\"1\"][\"recall\"]*class_report[\"1\"][\"support\"] + (1-class_report[\"0\"][\"recall\"])*class_report[\"0\"][\"support\"]} სესხის გაფუჭება, საიდანაც რეალურად გაფუჭებული იყო {str(round(class_report[\"1\"][\"precision\"], 4)*100)[0:5]} % ანუ {class_report[\"1\"][\"recall\"]*class_report[\"1\"][\"support\"]} სესი.\n",
    "\n",
    "რეალურად გაფუჭებული სესხებიდან მოდელმა სწორად აიდენტიფიცირა {str(round(class_report[\"1\"][\"recall\"], 4)*100)[0:5]} %\n",
    "\n",
    "რეალურად დაფარული სესხებიდან მოდელმა სწორად აიდენტიფიცირა {str(round(class_report[\"0\"][\"recall\"], 4)*100)[0:5]} %\n",
    "\n",
    "\n",
    "\n",
    "precision:  What proportion of positive identifications was actually correct?\n",
    "recall:     What proportion of actual positives was identified correctly?\n",
    "\n",
    "precision:  იდენტიფიცირებულების რა წილი იყო რეალურად სწორი?\n",
    "recall:     რეალურად სწორის რა წილი იყო სწორად იდენტიფიცირებული?\n",
    "\n",
    "            ''')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "366706a141483873",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "159a5b05cb77dbdf"
  },
  {
   "cell_type": "code",
   "source": [
    "#  creating a Logistic Regression model with specified parameters\n",
    "model = LogisticRegression(max_iter=1_000, class_weight='balanced', C=0.1)\n",
    "\n",
    "# creating a pipeline consisting of the WoE transformation step followed by the Logistic Regression model\n",
    "pipeline = Pipeline(steps=[('woe', woe_transform), ('logistic regression',model)])\n",
    "\n",
    "\n",
    "# train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "evaluate_model(pipeline)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60334ce1edbb62db",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# once validation is complete, retrain the model on full data\n",
    "pipeline.fit(X,y)\n",
    "Probability = pipeline.predict_proba(X)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad50be9467c8a40f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "scoring = CreditScoring(data=df, model=model, WoE_dict=WoE_dict, WoE_Binning=WoE_Binning, production=True)\n",
    "\n",
    "\n",
    "# allApproved_df = scoring.apply(allApproved_df).data\n",
    "# Rejected_df = scoring.apply(Rejected_df).data\n",
    "\n",
    "temp_df = scoring.apply(df)\n",
    "df = temp_df.data\n",
    "scorecard = temp_df.scorecard\n",
    "\n",
    "\n",
    "with open(model_dir + 'Step 3 (ScoreCard).pkl', 'wb') as file:\n",
    "    pickle.dump(scoring, file)"
   ],
   "id": "a9ee7da345bc11b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cutoff_plot(data):\n",
    "    \"\"\"\n",
    "    Generates a line plot of the approval rate over the bad rate using a specified cutoff range.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    data : pandas.DataFrame\n",
    "        A DataFrame containing columns 'Actual' and 'Scores' which are used for calculating \n",
    "        the approval and bad rates.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure\n",
    "        A line plot visualizing the approval rate over the bad rate.\n",
    "    \"\"\"\n",
    "    # initializing empty list for storing results\n",
    "    results = []\n",
    "\n",
    "    # iterating over the specified range and appending results\n",
    "    for j in range(20, 100, 5):\n",
    "        approve_rate = cutoff(Data=data[[\"Actual\", \"Scores\"]], Approved_Rate=j, Display=False)\n",
    "        results.append({\n",
    "            'Approve Rate': approve_rate[-1],\n",
    "            'Bad Rate': approve_rate[-2]\n",
    "        })\n",
    "\n",
    "    # converting the list of dictionaries into a DataFrame\n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    # plotting\n",
    "    return  Lineplot(Data=results, X_value='Bad Rate', Y_values=['Approve Rate'], Y_labels=['Model Approved'], Title=\"Approve Rate Over Bad Rate\",figsize=(12, 5))\n",
    "\n"
   ],
   "id": "7350e5fdecb89a02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Validation "
   ],
   "id": "8884eac6eaac45d3"
  },
  {
   "cell_type": "code",
   "source": [
    "# determine the cutoff score to achieve a desired approval rate and display the result\n",
    "cutoff_plot(df[[\"Actual\",\"Scores\"]])\n",
    "approve_rate = cutoff(Data=df[[\"Actual\",\"Scores\"]],Approved_Rate=87, Display=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96b60b24210e4283",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "summary(data = df, cutoff_score= approve_rate[0])"
   ],
   "id": "5b3b59623ba6cd28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "summary(data = df, cutoff_score= approve_rate[0], PDD=30)"
   ],
   "id": "e5c995b3c1a55b7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting risk for 6 months \n",
    "result = LivePD_Validation(Model_data = allApproved_df, PD_Live = PDLive, cutoff_score = approve_rate[0],result_path = res_data_plt_dir,  Title = \"Whole History PD30 SC1\")\n",
    "Lineplot(Data=result, X_value='MonthlyDate', Y_values=['Live30PercentA','Live30PercentB','Live30PercentF'], Y_labels=['Model Approved','Model Rejected','Without Model'],path=res_data_plt_dir, Title=\"Whole History PD30\",figsize=(12, 5))\n",
    "\n",
    "\n",
    "# plotting risk for full data\n",
    "allApproved_data = allApproved_df[allApproved_df[\"LoanValueDate\"] >= '2023-05-01']\n",
    "result = LivePD_Validation(Model_data = allApproved_data, PD_Live = PDLive, cutoff_score = approve_rate[0])\n",
    "Lineplot(Data=result, X_value='MonthlyDate', Y_values=['Live30PercentA','Live30PercentB','Live30PercentF'], Y_labels=['Model Approved','Model Rejected','Without Model'], path=res_data_plt_dir, Title=\"Last Year PD30 new\",figsize=(12, 5))\n",
    "\n",
    "\n",
    "# vintage ????\n",
    "result = Vintage_Validation(Model_data=allApproved_df, cutoff_score=approve_rate[0], result_path = res_data_plt_dir, Title = \"Whole History Vintage SC1\")\n",
    "Lineplot(Data=result, X_value='AppRegisterDate', Y_values=[\"Model\",\"Rejected\",\"TotalRisk\"], Y_labels=['Model Approved','Model Rejected','Without Model'], path=res_data_plt_dir, Title=\"Whole History Vintage\",figsize=(12, 5))\n",
    "\n"
   ],
   "id": "47c12593addf1f41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# score binning by scores\n",
    "result = Score_Binning_Validation(df=allApproved_df, bins=30, path=res_data_plt_dir, binning_type=1)\n",
    "Lineplot(Data=result, X_value='RowNumber', Y_values=[\"Risk\"], Y_labels=['Risk'], path=res_data_plt_dir,Title='score binning for scores',figsize=(12, 5))\n",
    "result"
   ],
   "id": "d71d109f0328f6e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "2a049971972467c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# score binning by percentiles\n",
    "result = Score_Binning_Validation(df=allApproved_df, bins=30, path=res_data_plt_dir, binning_type=2, title='idk')\n",
    "Lineplot(Data=result, X_value='RowNumber', Y_values=[\"Risk\"], Y_labels=['Risk'],figsize=(12, 5))\n",
    "result"
   ],
   "id": "cba8e50ce20da247",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# WoE_dict = woe_analysis.WoE_dict\n",
    "# Variable_Ranges = woe_analysis.Variable_Ranges\n",
    "# Variable_types = woe_analysis.Variable_types\n",
    "# IV_dict = woe_analysis.IV_dict\n",
    "# IV_excel = woe_analysis.IV_excel\n",
    "# \n",
    "# \n",
    "# df.to_pickle(res_data_pkl_dir + f\"Approved Scores with data.pkl\")\n",
    "# allApproved_df.to_pickle(res_data_pkl_dir  + f\"Whole Approved Scores with data.pkl\")\n",
    "# Rejected_df.to_pickle(res_data_pkl_dir  + f\"Rejected Data Approved by Model.pkl\")\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# scorecard.to_excel(res_dir + f\"Scorecard.xlsx\", index=False)\n",
    "# df.to_excel(res_data_exl_dir + f\"Approved Scores with data.xlsx\", index=False)\n",
    "# IV_excel.to_excel(res_dir + f\"Manual Final IV.xlsx\", index=False)\n",
    "# allApproved_df.to_excel(res_data_exl_dir + f\"Whole Approved Scores with data.xlsx\")\n",
    "# Rejected_df.to_excel(res_data_exl_dir + f\"Rejected Data Approved by Model.xlsx\", index=False)\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# # Save the variables directly to a .pkl file\n",
    "# with open(model_dir + 'Variables.pkl', 'wb') as file:\n",
    "#     dill.dump({'WoE_dict': WoE_dict, 'Variable_Ranges': Variable_Ranges, 'Variable_types': Variable_types, 'IV_dict': IV_dict, 'IV_excel': IV_excel}, file)\n"
   ],
   "id": "3d145edb1aaebbd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "be312343f9130608",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "5edbe4653f403813",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
